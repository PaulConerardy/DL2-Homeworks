{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMK2-PaulConerardy-1106073.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09f28edbd0d54e43918a98fa0050ad83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33e9b0c2715443779086041467122057",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0de73dbf5bae47b7a7a4900026d9390f",
              "IPY_MODEL_eac3183b151a43318f0093d13d30675a"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "33e9b0c2715443779086041467122057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "0de73dbf5bae47b7a7a4900026d9390f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f30a0d6acfc74dbcb8496a44f4cdc7a1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a79f6e819095470b9cfb7238dc04f754"
          },
          "model_module_version": "1.5.0"
        },
        "eac3183b151a43318f0093d13d30675a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38b53f0ac5a147efa0acb0aa6c5e0f91",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [00:04&lt;00:00, 93.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d030e88f3d984ff7aeaf9849d7c9db7c"
          },
          "model_module_version": "1.5.0"
        },
        "f30a0d6acfc74dbcb8496a44f4cdc7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "a79f6e819095470b9cfb7238dc04f754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "38b53f0ac5a147efa0acb0aa6c5e0f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "d030e88f3d984ff7aeaf9849d7c9db7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "80353b62ce1b4530be1c606e2e79723d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf104a0e40e34f05b16c8be55a1c96fb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9feb6d5d860d45529e7cfe6b1ca3cef0",
              "IPY_MODEL_8fe0b340f7224999bbdfcf178cb8d1eb"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "bf104a0e40e34f05b16c8be55a1c96fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "9feb6d5d860d45529e7cfe6b1ca3cef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca4f6d6069724ec9bda9c30201980c21",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 227845,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 227845,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af2f1985c7f544c8bde99867c2627d86"
          },
          "model_module_version": "1.5.0"
        },
        "8fe0b340f7224999bbdfcf178cb8d1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a78c11bd9fdd412ca53cc8f9a745d5e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 228k/228k [00:02&lt;00:00, 77.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3225df3adbcc4eadb95e05c0f11e2e08"
          },
          "model_module_version": "1.5.0"
        },
        "ca4f6d6069724ec9bda9c30201980c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "af2f1985c7f544c8bde99867c2627d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "a78c11bd9fdd412ca53cc8f9a745d5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "3225df3adbcc4eadb95e05c0f11e2e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "13296676e4a84bb295e57590d82d6662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6c3253af8624f249b44f1b2d497fe50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5aa3da7943a0407b9f80aec6e091aa24",
              "IPY_MODEL_8a1bffb41ef04fc895a2fe7a3f97c991"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "d6c3253af8624f249b44f1b2d497fe50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "5aa3da7943a0407b9f80aec6e091aa24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_568c0f36531a4f72a762f030f0c0f406",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442221694,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442221694,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6302ab57b3a34f31badb0f12440d4c97"
          },
          "model_module_version": "1.5.0"
        },
        "8a1bffb41ef04fc895a2fe7a3f97c991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36e68503e9b5416395a86d05eba93ccd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442M/442M [00:08&lt;00:00, 53.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1842d82b6a764a3a8e516e10eb4aedd4"
          },
          "model_module_version": "1.5.0"
        },
        "568c0f36531a4f72a762f030f0c0f406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "6302ab57b3a34f31badb0f12440d4c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "36e68503e9b5416395a86d05eba93ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "1842d82b6a764a3a8e516e10eb4aedd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCCR3YZXRquZ"
      },
      "source": [
        "# HMK 2\n",
        "\n",
        "Paul Conerardy\n",
        "11206073\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLPISabkSRWA"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "This notebook will only presents the model that offered me the best performance on Kaggle but a few more were tried.\n",
        "\n",
        "The final model used is SciBERT (cf: https://www.aclweb.org/anthology/D19-1371.pdf) which is a pretrained language model based on BERT that was specifically trained on a corpus of scientific texts.\n",
        "\n",
        "The model is adjusted using the library \"transformers\" by HuggingFace. The title of the paper will be concatenated with its abstract and then go through a few trasnformations. The text will be cleaned by removing any URLs, hashtags, non-alphanumeric characters, etc... but also any stopwords (words without any semantic meaning). The idea behind this transformation is to focus on the vocabulary specific to each scientific field that we have to classify. \n",
        "\n",
        "Since the distribution of the different labels is very unbalanced (displayed at the end of this notebook), a weighting will be applied when computing the cross entropy loss. Those weightings were empirically chosen after a few tries. \n",
        "\n",
        "Moreover, since BERT is a lot less complex than other modern transformer models (like RoBERTa) this allows us to try to maximize the maximum sequence length of text considered for each observation since we are still limited VRAM-wise.\n",
        "\n",
        "Finally, since our dataset is relatively small (60k observations) and after finding an acceptable configuration, I tried to use the dataset almost entirely for training (keeping only 5% for validation and no test set) to try to maximize my performance on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kLht5cYSlJS",
        "outputId": "3273ab76-08ba-4914-ed33-ed4bac4d12af"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import networkx as nx\n",
        "\n",
        "from tensorflow import keras\n",
        "import torch\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=77298e726de4b89764c3dbe3e393af8c7dc03acf9da3c693d47f12a6472e42db\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 5.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5QyuhN0SqTG",
        "outputId": "2996ae4f-4c53-40b3-80af-69e0df71470e"
      },
      "source": [
        "import torch\n",
        "\n",
        "# GPU runtime\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU used:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU used: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpTs79l7SwJ5"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESgoLxmJSz1M",
        "outputId": "5bef0359-7fc1-451c-f9ba-360df8c6f084"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYXrgc3_S0rJ"
      },
      "source": [
        "path='/content/drive/MyDrive/Colab Notebooks/ML2/Hmk2/data'\n",
        "\n",
        "train = pd.read_csv(path + \"/train.csv\", names=[\"label\", \"node idx\"])\n",
        "test = pd.read_csv(path + \"/test.csv\", names=[\"node idx\"])\n",
        "text = pd.read_csv(path + \"/text.csv\", names=[\"paper id\", \"title\", \"abstract\"])\n",
        "\n",
        "node2paper = pd.read_csv(path + \"/nodeid2paperid.csv\")\n",
        "sample = pd.read_csv(path + \"/sample.csv\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6nbWrucS4Sl"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "aZe1ZvywS-Px",
        "outputId": "472aadde-44fd-4bb6-e816-438c65d3214b"
      },
      "source": [
        "# Data merging to link the ids and the text\n",
        "\n",
        "reference = node2paper\n",
        "\n",
        "df = pd.merge(train, reference, on=\"node idx\")\n",
        "df = pd.merge(df, text, on = \"paper id\")\n",
        "\n",
        "print('Number of observations: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of observations: 60,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>node idx</th>\n",
              "      <th>paper id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>9657784</td>\n",
              "      <td>evasion attacks against machine learning at te...</td>\n",
              "      <td>In security-sensitive applications, the succes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>39886162</td>\n",
              "      <td>how hard is computing parity with noisy commun...</td>\n",
              "      <td>We show a tight lower bound of $\\Omega(N \\log\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>121432379</td>\n",
              "      <td>a promise theory perspective on data networks</td>\n",
              "      <td>Networking is undergoing a transformation thro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1444859417</td>\n",
              "      <td>webvrgis based city bigdata 3d visualization a...</td>\n",
              "      <td>This paper shows the WEBVRGIS platform overlyi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1483430697</td>\n",
              "      <td>information theoretic authentication and secre...</td>\n",
              "      <td>In the splitting model, information theoretic ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                           abstract\n",
              "0      4  ...  In security-sensitive applications, the succes...\n",
              "1      5  ...  We show a tight lower bound of $\\Omega(N \\log\\...\n",
              "2      8  ...  Networking is undergoing a transformation thro...\n",
              "3      6  ...  This paper shows the WEBVRGIS platform overlyi...\n",
              "4      4  ...  In the splitting model, information theoretic ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIa8k1A7TNv4"
      },
      "source": [
        "# Concatenation of the paper's title and abstract and conversion to arrays\n",
        "\n",
        "df['text'] = df['title'] + ' ' +df['abstract']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FX_eKggXi3z"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.str.lower() # lowercase\n",
        "    text = text.str.replace(r\"\\#\",\"\") # replaces hashtags\n",
        "    text = text.str.replace(r\"http\\S+\",\"URL\")  # remove URL addresses\n",
        "    text = text.str.replace(r\"@\",\"\")\n",
        "    text = text.str.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \")\n",
        "    text = text.str.replace(\"\\s{2,}\", \" \")\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aan5VP9lGVG5",
        "outputId": "62435671-b797-4ea7-aa8b-4ffe14f47a8f"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-M__E8CGhRO"
      },
      "source": [
        "stop = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bC7-qinhHh1M",
        "outputId": "c8bf45b2-7496-4397-b91e-fae72a055dd5"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>node idx</th>\n",
              "      <th>paper id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>9657784</td>\n",
              "      <td>evasion attacks against machine learning at te...</td>\n",
              "      <td>In security-sensitive applications, the succes...</td>\n",
              "      <td>evasion attacks against machine learning at te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>39886162</td>\n",
              "      <td>how hard is computing parity with noisy commun...</td>\n",
              "      <td>We show a tight lower bound of $\\Omega(N \\log\\...</td>\n",
              "      <td>how hard is computing parity with noisy commun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>121432379</td>\n",
              "      <td>a promise theory perspective on data networks</td>\n",
              "      <td>Networking is undergoing a transformation thro...</td>\n",
              "      <td>a promise theory perspective on data networks ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1444859417</td>\n",
              "      <td>webvrgis based city bigdata 3d visualization a...</td>\n",
              "      <td>This paper shows the WEBVRGIS platform overlyi...</td>\n",
              "      <td>webvrgis based city bigdata 3d visualization a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1483430697</td>\n",
              "      <td>information theoretic authentication and secre...</td>\n",
              "      <td>In the splitting model, information theoretic ...</td>\n",
              "      <td>information theoretic authentication and secre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                               text\n",
              "0      4  ...  evasion attacks against machine learning at te...\n",
              "1      5  ...  how hard is computing parity with noisy commun...\n",
              "2      8  ...  a promise theory perspective on data networks ...\n",
              "3      6  ...  webvrgis based city bigdata 3d visualization a...\n",
              "4      4  ...  information theoretic authentication and secre...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQd8kBxGtjl"
      },
      "source": [
        "# We create a column with no stopwords and \"clean\" text\n",
        "\n",
        "df['text'] = clean_text(df['text'])\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "#df[\"text\"] = df[\"text\"].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split() ]))\n",
        "df[\"text\"] = clean_text(df[\"text\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzMFKtAgHjKe",
        "outputId": "9dbc5819-a03b-432d-d5ac-0abaad4fc1be"
      },
      "source": [
        "df['text'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    evasion attacks machine learning test time sec...\n",
              "1    hard computing parity noisy communications sho...\n",
              "2    promise theory perspective data networks netwo...\n",
              "3    webvrgis based city bigdata 3d visualization a...\n",
              "4    information theoretic authentication secrecy c...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlljcGK-G2mY"
      },
      "source": [
        "text = df.text.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzLZc9UITa7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "09f28edbd0d54e43918a98fa0050ad83",
            "33e9b0c2715443779086041467122057",
            "0de73dbf5bae47b7a7a4900026d9390f",
            "eac3183b151a43318f0093d13d30675a",
            "f30a0d6acfc74dbcb8496a44f4cdc7a1",
            "a79f6e819095470b9cfb7238dc04f754",
            "38b53f0ac5a147efa0acb0aa6c5e0f91",
            "d030e88f3d984ff7aeaf9849d7c9db7c",
            "80353b62ce1b4530be1c606e2e79723d",
            "bf104a0e40e34f05b16c8be55a1c96fb",
            "9feb6d5d860d45529e7cfe6b1ca3cef0",
            "8fe0b340f7224999bbdfcf178cb8d1eb",
            "ca4f6d6069724ec9bda9c30201980c21",
            "af2f1985c7f544c8bde99867c2627d86",
            "a78c11bd9fdd412ca53cc8f9a745d5e2",
            "3225df3adbcc4eadb95e05c0f11e2e08"
          ]
        },
        "outputId": "323f2641-ad8b-48cd-e2cb-7e07c263d6fe"
      },
      "source": [
        "# Instantiate the tokenizer (SciBERT)\n",
        "# List of pretrained models : https://huggingface.co/transformers/pretrained_models.html\n",
        "\n",
        "\n",
        "from transformers import DebertaV2Tokenizer, RobertaTokenizer, AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased',do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09f28edbd0d54e43918a98fa0050ad83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80353b62ce1b4530be1c606e2e79723d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=227845.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYJ2AusITxCT",
        "outputId": "bd5d4f09-d18e-4ed1-aaab-6a15049e620d"
      },
      "source": [
        "# Test of the tokenization process\n",
        "print('Original sentence: ', text[0])\n",
        "print('Tokenized sentence: ', tokenizer.tokenize(text[0]))\n",
        "print('Tokens IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence:  evasion attacks machine learning test time security sensitive applications success machine learning depends thorough vetting resistance adversarial data one pertinent well motivated attack scenario adversary may attempt evade deployed system test time carefully manipulating attack samples work present simple effective gradient based approach exploited systematically assess security several widely used classification algorithms evasion attacks following recently proposed framework security evaluation simulate attack scenarios exhibit different risk levels classifier increasing attacker's knowledge system ability manipulate attack samples gives classifier designer better picture classifier performance evasion attacks allows perform informed model selection (or parameter setting) evaluate approach relevant security task malware detection pdf files show systems easily evaded also sketch countermeasures suggested analysis\n",
            "Tokenized sentence:  ['ev', '##asion', 'attacks', 'machine', 'learning', 'test', 'time', 'security', 'sensitive', 'applications', 'success', 'machine', 'learning', 'depends', 'thorough', 'vet', '##ting', 'resistance', 'advers', '##arial', 'data', 'one', 'pertinent', 'well', 'motivated', 'attack', 'scenario', 'adversary', 'may', 'attempt', 'ev', '##ade', 'deployed', 'system', 'test', 'time', 'carefully', 'manipulating', 'attack', 'samples', 'work', 'present', 'simple', 'effective', 'gradient', 'based', 'approach', 'exploited', 'systematically', 'assess', 'security', 'several', 'widely', 'used', 'classification', 'algorithms', 'ev', '##asion', 'attacks', 'following', 'recently', 'proposed', 'framework', 'security', 'evaluation', 'simulate', 'attack', 'scenarios', 'exhibit', 'different', 'risk', 'levels', 'classifier', 'increasing', 'attacker', \"'\", 's', 'knowledge', 'system', 'ability', 'manipulate', 'attack', 'samples', 'gives', 'classifier', 'designer', 'better', 'picture', 'classifier', 'performance', 'ev', '##asion', 'attacks', 'allows', 'perform', 'informed', 'model', 'selection', '(', 'or', 'parameter', 'setting', ')', 'evaluate', 'approach', 'relevant', 'security', 'task', 'malware', 'detection', 'pdf', 'files', 'show', 'systems', 'easily', 'ev', '##aded', 'also', 'sketch', 'counter', '##measures', 'suggested', 'analysis']\n",
            "Tokens IDs:  [403, 22591, 7652, 3997, 1904, 856, 532, 3594, 4232, 2040, 2108, 3997, 1904, 3898, 9763, 17801, 586, 2661, 11440, 16754, 453, 482, 20662, 804, 10744, 3689, 4713, 15002, 552, 5809, 403, 932, 12160, 429, 856, 532, 9577, 23299, 3689, 1488, 697, 709, 2177, 2115, 4751, 791, 1139, 13294, 11810, 1285, 3594, 1323, 4276, 501, 2998, 2617, 403, 22591, 7652, 982, 2803, 1337, 2641, 3594, 2166, 9884, 3689, 5828, 5537, 643, 1265, 1049, 8039, 1953, 15244, 2505, 112, 1767, 429, 2495, 18884, 3689, 1488, 3669, 8039, 16337, 1883, 7295, 8039, 1150, 403, 22591, 7652, 2890, 620, 6841, 437, 2516, 145, 234, 2318, 2707, 546, 3138, 1139, 2884, 3594, 2188, 24870, 1995, 11815, 7208, 405, 1078, 3717, 403, 13504, 469, 18026, 4227, 21883, 2995, 669]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuiaXwWzUJTc",
        "outputId": "27cd4d4d-f232-4fd0-a885-082eb7ff1d30"
      },
      "source": [
        "inputs_id = []\n",
        "\n",
        "# Loop to tokenize the dataset\n",
        "for t in text:\n",
        "  encoded_sent = tokenizer.encode(t,\n",
        "                                  add_special_tokens=True)\n",
        "  \n",
        "  inputs_id.append(encoded_sent)\n",
        "\n",
        "print('Original sentence: ', text[0])\n",
        "print(' Tokens IDs:', inputs_id[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence:  evasion attacks machine learning test time security sensitive applications success machine learning depends thorough vetting resistance adversarial data one pertinent well motivated attack scenario adversary may attempt evade deployed system test time carefully manipulating attack samples work present simple effective gradient based approach exploited systematically assess security several widely used classification algorithms evasion attacks following recently proposed framework security evaluation simulate attack scenarios exhibit different risk levels classifier increasing attacker's knowledge system ability manipulate attack samples gives classifier designer better picture classifier performance evasion attacks allows perform informed model selection (or parameter setting) evaluate approach relevant security task malware detection pdf files show systems easily evaded also sketch countermeasures suggested analysis\n",
            " Tokens IDs: [102, 403, 22591, 7652, 3997, 1904, 856, 532, 3594, 4232, 2040, 2108, 3997, 1904, 3898, 9763, 17801, 586, 2661, 11440, 16754, 453, 482, 20662, 804, 10744, 3689, 4713, 15002, 552, 5809, 403, 932, 12160, 429, 856, 532, 9577, 23299, 3689, 1488, 697, 709, 2177, 2115, 4751, 791, 1139, 13294, 11810, 1285, 3594, 1323, 4276, 501, 2998, 2617, 403, 22591, 7652, 982, 2803, 1337, 2641, 3594, 2166, 9884, 3689, 5828, 5537, 643, 1265, 1049, 8039, 1953, 15244, 2505, 112, 1767, 429, 2495, 18884, 3689, 1488, 3669, 8039, 16337, 1883, 7295, 8039, 1150, 403, 22591, 7652, 2890, 620, 6841, 437, 2516, 145, 234, 2318, 2707, 546, 3138, 1139, 2884, 3594, 2188, 24870, 1995, 11815, 7208, 405, 1078, 3717, 403, 13504, 469, 18026, 4227, 21883, 2995, 669, 103]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvdctDCSUrgV"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 350\n",
        "# Sequence padding to get sequences of size MAX_LEN\n",
        "inputs_id = pad_sequences(inputs_id, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FogE3D8iVDaW"
      },
      "source": [
        "# Attention mask to not consider padding ids in the model introduced just above\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "for sentence in inputs_id:\n",
        "  att_mask = [int(token_id > 0) for token_id in sentence]\n",
        "  attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5eldgHgVX-y"
      },
      "source": [
        "# Data splits\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(inputs_id, labels,\n",
        "                                                                                   random_state=42, test_size=0.05)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=42, test_size=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlJBqHeQVjLg"
      },
      "source": [
        "# Data to pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bVXR_0PVlPC"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raCkxWtEVtC5"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Batch_size will be selected to maximize the sequence length selected earlier while still being able to fit everything in memory\n",
        "batch_size = 20\n",
        "\n",
        "# Training DataLoader \n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Test DataLoader\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nA__tRnWFSl"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icrIDEhDP9DQ"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification, AdamW\n",
        "\n",
        "\n",
        "class SciBERT(torch.nn.Module):\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super(SciBERT, self).__init__()\n",
        "        \n",
        "        self.roberta = AutoModelForSequenceClassification.from_pretrained('allenai/scibert_scivocab_uncased', num_labels=768, return_dict=False, output_hidden_states = False,output_attentions = False) # Change?   :  RobertaForSequenceClassification + add linear layers ?\n",
        "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l1 = torch.nn.Linear(768, 64) \n",
        "        self.bn1 = torch.nn.LayerNorm(64)\n",
        "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l2 = torch.nn.Linear(64, 20)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.roberta(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
        "        # print(x)\n",
        "        # print(x.shape())\n",
        "        x = self.d1(x)\n",
        "        x = self.l1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.nn.Tanh()(x)\n",
        "        x = self.d2(x)\n",
        "        x = self.l2(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "13296676e4a84bb295e57590d82d6662",
            "d6c3253af8624f249b44f1b2d497fe50",
            "5aa3da7943a0407b9f80aec6e091aa24",
            "8a1bffb41ef04fc895a2fe7a3f97c991",
            "568c0f36531a4f72a762f030f0c0f406",
            "6302ab57b3a34f31badb0f12440d4c97",
            "36e68503e9b5416395a86d05eba93ccd",
            "1842d82b6a764a3a8e516e10eb4aedd4"
          ]
        },
        "id": "gyy9YEeMP_Th",
        "outputId": "c43dbba5-9fa2-40d1-8f27-ea2af5f2cd9e"
      },
      "source": [
        "model = SciBERT()\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13296676e4a84bb295e57590d82d6662",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442221694.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjxuKSS4XTlp"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3PWyG1qXVn-"
      },
      "source": [
        "# Adam Optimizer with Weight Decay\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5, \n",
        "                  eps = 1e-8) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8LMQBaNXb1B"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 12\n",
        "\n",
        "# Total number of training steps\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yszQLG1nXjTM"
      },
      "source": [
        "# Scoring function\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjiVFHHSXoup"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "# Function to get an idea of training time\n",
        "\n",
        "def format_time(elapsed):\n",
        "\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvTanvC9X2Zz"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyayaQpEX4VT",
        "outputId": "fdf00023-dade-4820-d4da-c9875345118d"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Print current training time and batch every 200 batch done\n",
        "        if step % 200 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack the inputs from our dataloader and attach them to the GPU\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "        # Forward pass\n",
        "        outputs = model(b_input_ids, \n",
        "                    #token_type_ids=None, \n",
        "                    attention_mask=b_input_mask\n",
        "                    #, labels=b_labels\n",
        "                    )\n",
        "        \n",
        "        weights = [1, 1.5, 1, 1, 1, 1, 1, 1.5, 1, 1, 1, 2, 1.5, 1, 1, 1, 0.6, 1, 1, 1]\n",
        "        class_weights = torch.FloatTensor(weights).cuda()\n",
        "        loss = torch.nn.CrossEntropyLoss(weight = class_weights)(outputs, b_labels)\n",
        "        total_loss += loss.item()\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the gradients to avoid \"exploding\" gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update optimizer and learning rate\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)               \n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "\n",
        "              # Validation\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Model set to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Move batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the current batch \n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Not computing gradients during validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(b_input_ids, \n",
        "                            #token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Store the probabilities per class outputed by Roberta\n",
        "        logits = outputs#[0]\n",
        "\n",
        "        # Detach output from GPU \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Call to the scoring function\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track training steps\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Accuracy score obtained and time necessary to perform one epoch \n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======== Epoch 1 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:19.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:18.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:57.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:17.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:56.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:35.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:55.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:34.\n",
            "\n",
            "  Average training loss: 1.15\n",
            "  Training epcoh took: 0:18:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 2 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:20.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:18.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:58.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:17.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:57.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:36.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:55.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:35.\n",
            "\n",
            "  Average training loss: 0.80\n",
            "  Training epcoh took: 0:18:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 3 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:20.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:18.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:58.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:17.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:57.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:36.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:55.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:35.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:18:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 4 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:20.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:19.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:58.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:17.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:57.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:36.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:56.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:35.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:18:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 5 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:20.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:19.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:58.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:18.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:57.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:36.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:56.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:35.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:18:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 6 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:20.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:19.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:58.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:17.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:57.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:36.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:56.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:35.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:18:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 7 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:20.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:19.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:58.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:17.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:56.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:36.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:55.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:35.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:18:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 8 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:20.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:18.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:58.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:17.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:37.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:57.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:36.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:55.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:15.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:35.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:18:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 9 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:20.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:59.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:18.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:38.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:57.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:17.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:36.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:56.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:16.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:35.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:55.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:14.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:34.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:18:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 10 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:19.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:58.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:18.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:37.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:57.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:16.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:36.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:55.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:15.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:34.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:54.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:13.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:32.\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:18:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 11 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:19.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:58.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:18.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:37.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:57.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:16.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:35.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:55.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:14.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:34.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:53.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:13.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:32.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:18:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n",
            "======== Epoch 12 / 12 ========\n",
            "  Batch   200  of  2,850.    Elapsed: 0:01:19.\n",
            "  Batch   400  of  2,850.    Elapsed: 0:02:39.\n",
            "  Batch   600  of  2,850.    Elapsed: 0:03:58.\n",
            "  Batch   800  of  2,850.    Elapsed: 0:05:18.\n",
            "  Batch 1,000  of  2,850.    Elapsed: 0:06:37.\n",
            "  Batch 1,200  of  2,850.    Elapsed: 0:07:57.\n",
            "  Batch 1,400  of  2,850.    Elapsed: 0:09:16.\n",
            "  Batch 1,600  of  2,850.    Elapsed: 0:10:35.\n",
            "  Batch 1,800  of  2,850.    Elapsed: 0:11:55.\n",
            "  Batch 2,000  of  2,850.    Elapsed: 0:13:14.\n",
            "  Batch 2,200  of  2,850.    Elapsed: 0:14:34.\n",
            "  Batch 2,400  of  2,850.    Elapsed: 0:15:53.\n",
            "  Batch 2,600  of  2,850.    Elapsed: 0:17:13.\n",
            "  Batch 2,800  of  2,850.    Elapsed: 0:18:32.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:18:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udfUH6w4ZD6V"
      },
      "source": [
        "# Preparing the dataset for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voBJ17okZJ0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bb3504-b424-4c39-a6e0-99c53480c629"
      },
      "source": [
        "\n",
        "test = pd.read_csv(path + \"/test.csv\", names=[\"node idx\"])\n",
        "text = pd.read_csv(path + \"/text.csv\", names=[\"paper id\", \"title\", \"abstract\"])\n",
        "\n",
        "# Same treatment as the training dataset\n",
        "test = pd.merge(test, reference, on=\"node idx\")\n",
        "test = pd.merge(test, text, on = \"paper id\")\n",
        "\n",
        "df = test\n",
        "df['text'] = df['title'] + ' ' +df['abstract']\n",
        "\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "titles_test = df.text.values\n",
        "\n",
        "# Call to the same tokenizer as the training set\n",
        "input_ids = []\n",
        "\n",
        "for t in titles_test:\n",
        "\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        t,                   \n",
        "                        add_special_tokens = True\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Padding\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Attention mask\n",
        "attention_masks = []\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# To pytorch tensors\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "batch_size = 32  \n",
        "\n",
        "# Pytorch dataLoader\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 13,718\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTWwQpaecsQn"
      },
      "source": [
        "# Predictions and submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YgEekkJcrwe"
      },
      "source": [
        "# Model set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  b_input_ids, b_input_mask = batch\n",
        "  \n",
        "  # Not computing gradients during testing\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids,# token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs\n",
        "\n",
        "  # Detach outputed results from GPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  \n",
        "# Argmax on the outputed probabilities to find the chosen label\n",
        "predictions_test = []\n",
        "for i in range(len(predictions)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  predictions_test.append(pred_labels_i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHaMnomPdYf1"
      },
      "source": [
        "# Predicted labels formatted into a single list\n",
        "flat_list = []\n",
        "for sublist in predictions_test:\n",
        "    for item in sublist:\n",
        "        flat_list.append(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfxNiGG2d4iw"
      },
      "source": [
        "# Load the initial file and append the predictions\n",
        "verif = pd.read_csv(path +'/test.csv', names=['id'])\n",
        "flat_list = list(map(int, flat_list))\n",
        "verif['label'] = flat_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CvCusejeJhS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "48df9052-2e0f-4940-e64a-62dfd0bf58a3"
      },
      "source": [
        "# Verify the distribution of predicted labels\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(40, 8))\n",
        "sns.countplot(x='label', data=verif)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2880x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arrLpZ9iePWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5c2d82b1-4afa-424e-f02e-37f12afece67"
      },
      "source": [
        "# Can compare it to the distribution of labels in the training set\n",
        "plt.figure(figsize=(40, 8))\n",
        "sns.countplot(x='label', data=train)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2880x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh5HBDhseYg2"
      },
      "source": [
        "# Save the submission file in a format that Kaggle will accept\n",
        "verif.to_csv('sub_SciBERT.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDNf0Ug_SV2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ae0badb7-de16-4099-cfef-b495ff48c23e"
      },
      "source": [
        "verif.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>137832</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>137833</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>137834</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>137836</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>137837</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  label\n",
              "0  137832     16\n",
              "1  137833      4\n",
              "2  137834     10\n",
              "3  137836      5\n",
              "4  137837      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}